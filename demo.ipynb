{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c457f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from label_generation import generate_labels\n",
    "from label_clustering import cluster_labels_gpt, make_clustering_prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bbff1f",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8ac0125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from Hugging Face\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"jhu-clsp/astro-llms-full-query-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ead96fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1716992594_0',\n",
       "  '<@U07524ZQSD8> How many papers published in 2022 used data from MAST missions?'),\n",
       " ('1716992673_0',\n",
       "  '<@U07524ZQSD8> Can JWST measure unambiguous biosignatures in exoplanet atmospheres?'),\n",
       " ('1716992727_0', '<@U07524ZQSD8> What is the value of the Hubble Constant?')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a dictionary where keys are thread id and values are full user query\n",
    "data_processed = {}\n",
    "full_data = False\n",
    "n_samples = len(ds['train']) if full_data else 10\n",
    "for i in range(n_samples):\n",
    "    segment_id = 0 # some datasets have multiple segments per document, here we only use 0 as there is only one segment\n",
    "    thread_id = str(ds['train'][i]['thread_ts']) + '_' + str(segment_id)\n",
    "    data_processed[thread_id] = ds['train'][i]['full_user_query']\n",
    "# print first 3 items\n",
    "list(data_processed.items())[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47915795",
   "metadata": {},
   "source": [
    "## Label Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53727bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for pipeline\n",
    "config = {\n",
    "    # Generation Model \n",
    "\"model_name\": \"gpt-4o-mini\",\n",
    "\n",
    "# Data\n",
    "\"dataset_name\": \"values\",\n",
    "\"dataset_path\": \"/data/afield6/oida_data/processed/values/\", # Change Me\n",
    "\n",
    "# Results\n",
    "\"output_dir_root\": \"/data/afield6/oida_results/generation/\", # Change Me\n",
    "\n",
    "# CLustering\n",
    "\"cluster_model_name\": \"gpt-4o-mini\",\n",
    "\"cluster_output_dir\": \".\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8a1ad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system prompt for label generation\n",
    "system_prompt = \"\"\"\n",
    "We are using the queries to this bot to conduct INDUCTIVE CODING. \n",
    "The coding aims to understand what type of questions or user intent these scientists use to raise queries.\n",
    "\n",
    "Instruction:\n",
    "- Label the input only when it is HIGHLY RELEVANT and USEFUL for understanding the user intent for querying the literature search bot from the astronomy scientists.\n",
    "- Then, define the phrase of the label. The label description should be observational, concise and clear.\n",
    "- ONLY output the label and DO NOT output any explanation.\n",
    "\n",
    "Format:\n",
    "- Define the label using the format \\\"LABEL: [The phrase of the label]\\\". \n",
    "- If there are multiple labels, each label is a new line. \n",
    "- If the input is irrelevant, use \\\"LABEL: [Irrelevant]\\\". \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13008783",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.43s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'1716992594': {'LLM_Annotation': [{'sentence': '<@U07524ZQSD8> How many papers published in 2022 used data from MAST missions?',\n",
       "    'label': ['Inquiry about publication statistics using specific data sources']}]},\n",
       " '1716992673': {'LLM_Annotation': [{'sentence': '<@U07524ZQSD8> Can JWST measure unambiguous biosignatures in exoplanet atmospheres?',\n",
       "    'label': ['Biosignature detection in exoplanet atmospheres']}]},\n",
       " '1716992727': {'LLM_Annotation': [{'sentence': '<@U07524ZQSD8> What is the value of the Hubble Constant?',\n",
       "    'label': ['Inquiry about a specific astronomical constant']}]},\n",
       " '1716992771': {'LLM_Annotation': [{'sentence': '<@U07524ZQSD8> What sort of questions can you answer? Provide your response in the form of a bulleted list.',\n",
       "    'label': ['User inquiry about capabilities']}]},\n",
       " '1716992843': {'LLM_Annotation': [{'sentence': '<@U07524ZQSD8> How is the emission spectrum of a sunspot different from the spectrum of the solar photosphere?',\n",
       "    'label': ['Comparative analysis of emission spectra']}]},\n",
       " '1716992981': {'LLM_Annotation': [{'sentence': '<@U07524ZQSD8> How many papers related to brown dwarf science were published in 2022?',\n",
       "    'label': ['Query for publication statistics']}]},\n",
       " '1716993026': {'LLM_Annotation': [{'sentence': '<@U07524ZQSD8> How many papers related to cosmic noon were published in 2023?',\n",
       "    'label': ['Inquiry about specific publication count related to cosmic noon']}]},\n",
       " '1716993050': {'LLM_Annotation': [{'sentence': '<@U07524ZQSD8> what are the most promising subfields of astronomical research for new discoveries?',\n",
       "    'label': ['Inquiry about promising research areas']}]}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_result = generate_labels(data_processed, system_prompt, config)\n",
    "gen_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4dc534",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "623ca94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Run gpt-4o-mini Clustering=========\n",
      "Number of batches: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.23s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'User Capabilities Inquiry': ['User inquiry about capabilities',\n",
       "  'Query for publication statistics'],\n",
       " 'Research Focus Areas': ['Inquiry about promising research areas',\n",
       "  'Inquiry about specific publication count related to cosmic noon'],\n",
       " 'Publication Statistics': ['Inquiry about publication statistics using specific data sources'],\n",
       " 'Astrophysical Research Topics': ['Biosignature detection in exoplanet atmospheres',\n",
       "  'Inquiry about a specific astronomical constant',\n",
       "  'Comparative analysis of emission spectra']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"astrobot\"\n",
    "cluster_prompt = make_clustering_prompt(dataset=dataset)\n",
    "cluster_labels_gpt(gen_result, cluster_prompt, config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe6ecf0",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2087481",
   "metadata": {},
   "source": [
    "### Theme precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13330579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c12348a",
   "metadata": {},
   "source": [
    "### Segment Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e5913e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oida",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
